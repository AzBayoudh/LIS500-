<!DOCTYPE html>
<html lang="en">
 <head>
   <meta charset="UTF-8" />
   <meta name="viewport" content="width=device-width, initial-scale=1.0" />
   <title>Machine Learning Project</title>

   <!-- Bootstrap -->
   <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet"
     integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">

   <!-- My styles -->
   <link href="styles.css" rel="stylesheet" />

   <!-- p5 + sound + ml5 for Teachable Machine -->
   <script src="https://cdn.jsdelivr.net/npm/p5@1.11.1/lib/p5.min.js"></script>
   <script src="https://cdn.jsdelivr.net/npm/p5@1.11.1/lib/addons/p5.sound.min.js"></script>
   <script src="https://unpkg.com/ml5@latest/dist/ml5.min.js"></script>



 <body>
   <!-- Site header and navigation -->
   <header>
     <nav class="container my-3">
       <a class="btn btn-outline-primary btn-sm me-2" href="index.html">Home</a>
       <a class="btn btn-outline-primary btn-sm me-2" href="about.html">About Us</a>
       <a class="btn btn-outline-primary btn-sm me-2" href="resources.html">Resources</a>
       <a class="btn btn-outline-primary btn-sm me-2" href="hero.html">Tech Hero</a>
       <a class="btn btn-primary btn-sm me-2" href="machine-learning.html" aria-current="page">Machine Learning</a>
     </nav>
   </header>

   <main class="container">
     <h1>Teachable Machine: Voice Classifier</h1>
     <p>
       On this page, we‚Äôre showcasing a sound-based machine learning project we built together using Google‚Äôs
       Teachable Machine. Our goal was to teach a simple model to recognize <strong>YES</strong>, <strong>NO</strong>,
       and <strong>QUIET</strong> through voice input. It‚Äôs a small example of how AI systems ‚Äúlearn‚Äù from the data
       humans feed them ‚Äî and how bias can easily sneak into that process.
     </p>

     <div class="intro-box">
       <h2 class="h5">Live Demo</h2>
       <p>
         When your browser asks for microphone permission, click <strong>Allow</strong>. Then try saying
         ‚ÄúYES,‚Äù ‚ÄúNO,‚Äù or staying quiet and watch how the emoji changes in real time.
       </p>
       <p class="text-muted">
         The canvas below is generated with p5.js and ml5.js and shows our live Teachable Machine sound classifier.
       </p>
        <a href="https://editor.p5js.org/MomenJaber01/full/TuR_lFkJH" target="_blank"><strong>Click on this link to give it a try!</strong> </a>
     </div>

     <div class="intro-box">
       <h2 class="h5">Demo Video</h2>
       <p>
         This short video records our Teachable Machine model in action as we trigger each class.
       </p>
       <iframe width="650" height="415"
        src="<iframe width="560" height="315" src="https://www.youtube.com/embed/LELSG6Frcv0?si=pUAsA4rik1F9_CDR&amp;start=1" title="YouTube video player" 
        frameborder="0" 
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" 
        referrerpolicy="strict-origin-when-cross-origin" 
        allowfullscreen></iframe>">
       </iframe>
     </div>

     <div class="intro-box">
       <h2 class="h5">Project Statement &amp; Reflection</h2>

       <!-- üîπ Aziz‚Äôs Sections: Intro + Training -->
       <h3>Intro & Model Training</h3>
       <p>
         For this project, our group decided to build a Teachable Machine that could recognize sound. We wanted something
         simple but interactive, so we trained a model that listens for three categories ‚Äî <strong>YES</strong>,
         <strong>NO</strong>, and <strong>QUIET</strong>. The idea was to explore how training data shapes a model‚Äôs behavior
         and connect that experience to the ideas from Joy Buolamwini‚Äôs <em>Unmasking AI</em>.
       </p>

       <p>
         I handled most of the training process and the setup for connecting our model to the website. We started by recording
         voice samples,  each of us saying ‚ÄúYES‚Äù and ‚ÄúNO‚Äù multiple times and capturing a few seconds of silence for ‚ÄúQUIET.‚Äù
         Our first version didn‚Äôt perform great. The model kept mixing things up and reacting to background noise. That made
         us realize how much the results depend on the data you feed it. We retrained it with more balanced samples, focusing
         on clearer, consistent recordings.
       </p>

       <p>
         Even after that, the model recognized my voice better than my partners‚Äô. It struggled with different tones and accents,
         which really connected to what Joy Buolamwini writes about, how algorithmic bias starts from uneven data. If a system
         is only trained on a narrow range of input, it‚Äôll work best for people who match that input and less accurately for
         everyone else. It‚Äôs a small project, but it shows how bias can appear even without bad intentions.
       </p>

       <p>
         Once the model worked, I used <code>ml5.js</code> and <code>p5.js</code> to integrate it into our site. It took a few
         tries, I kept running into missing script errors and wrong model URLs, but eventually it came together. Watching the
         emoji respond in real time to our voices was honestly cool. It made all the debugging worth it and gave us something
         visual to share on this page.
       </p>

       <!-- üîπ Partner Placeholder: Testing & Demo -->
       <h3>[Partner 1: Testing & Demo]</h3>
       <p>
         [This section will cover how we tested the model together, recorded the demo video, and what we observed when different
         people or environments affected accuracy.]
       </p>

       <!-- üîπ Partner Placeholder: Reflection on Unmasking AI -->
       <h3>[Partner 2: Reflection on Unmasking AI]</h3>
       <p>
         [This section will focus on how our group connected what we learned during the project to Joy Buolamwini‚Äôs
         <em>Unmasking AI</em>. It should talk about algorithmic bias, fairness, representation, and how small projects like ours
         mirror larger issues in AI.]
       </p>

       <!-- üîπ Placeholder for Group Conclusion -->
       <h3>[Group Conclusion]</h3>
       <p>
         [This section will summarize what the group learned overall, about bias, teamwork, and human choices in training
         machine learning models. It can tie everything together for the final version.]
       </p>
     </div>

     <div class="intro-box">
       <h2 class="h5">Project Details</h2>
       <ul>
         <li><strong>Group Members:</strong> Aziz Bayoudh, Momen Jaber, [Partner 2 Name?]</li>
         <li><strong>Tool:</strong> Teachable Machine (Sound Project) + p5.js + ml5.js</li>
         <li><strong>GitHub Repo:</strong>
           <a href="https://github.com/AzBayoudh/LIS500-" target="_blank">View project code on GitHub</a>
         </li>
       </ul>
     </div>
   </main>
 </body>
</html>
